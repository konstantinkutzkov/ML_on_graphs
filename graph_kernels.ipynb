{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74dc9f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc, roc_auc_score as auc\n",
    "from sklearn import svm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dot, Embedding, Flatten, Dense\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b399129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_node_labels(filename_nodes_to_graph, filename_node_labels, nr_graphs):\n",
    "    \n",
    "    with open(filename_nodes_to_graph) as f_nodes:\n",
    "        nodes = f_nodes.read().splitlines()\n",
    "        \n",
    "    with open(filename_node_labels) as f_labels:\n",
    "        labels = f_labels.read().splitlines()\n",
    "    \n",
    "    if (len(nodes) != len(labels)):\n",
    "        raise ValueError('Node lists of different length')\n",
    "        return -1\n",
    "    \n",
    "    Vs = [{} for _ in range(nr_graphs)]\n",
    "    nodes_to_graph = {}\n",
    "    node_labels = {}\n",
    "    set_labels = set()\n",
    "    for i in range(len(nodes)):\n",
    "        node_id = i+1\n",
    "        graph_id = int(nodes[i])\n",
    "        nodes_to_graph[node_id] = graph_id\n",
    "        label = labels[i]\n",
    "        set_labels.add(label)\n",
    "        node_labels[node_id] = label\n",
    "        Vs[graph_id][node_id] = label\n",
    "    return Vs, nodes_to_graph, node_labels, set_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "569a4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_edges(filename_edges, Vs, nodes_to_graph, node_labels, nr_graphs, sep=','):\n",
    "    Es = [{} for _ in range(nr_graphs)]\n",
    "    f_edges = open(filename_edges, 'r')\n",
    "    for line in f_edges: \n",
    "        line_split = str.split(line, sep)\n",
    "        e1 = int(line_split[0].strip())\n",
    "        e2 = int(line_split[1].strip())\n",
    "        if (nodes_to_graph[e1] != nodes_to_graph[e2]):\n",
    "            print('Vertices connected by and edge but belonging to different graphs')\n",
    "            print('nodes',  e1, e2)\n",
    "            print('graphs', nodes_to_graph[e1], nodes_to_graph[e2])\n",
    "        E = Es[nodes_to_graph[e1]]  \n",
    "        L = []\n",
    "        if e1 in E:\n",
    "            L = E[e1]\n",
    "        L.append(e2)\n",
    "        E[e1] = L\n",
    "        #Es[nodes_to_graph[e1]] = E\n",
    "    return Es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2b5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph(folderpath, filename):\n",
    "    '''\n",
    "    A method for reading graphs in the format provided in \n",
    "    https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets\n",
    "    '''\n",
    "    \n",
    "    filename_edges = folderpath + '/' + filename + '/' + filename + '_A.txt'\n",
    "    filename_nodes_to_graph = folderpath + '/' + filename + '/' + filename + '_graph_indicator.txt'\n",
    "    filename_node_labels = folderpath + '/' + filename + '/' + filename + '_node_labels.txt'\n",
    "    filename_classes = folderpath + '/' + filename + '/' + filename + '_graph_labels.txt'\n",
    "    \n",
    "    print(filename_edges)\n",
    "    \n",
    "    classes = []\n",
    "    with open(filename_classes) as f_classes:\n",
    "        classes_f = f_classes.read().splitlines()  \n",
    "        for c in classes_f:\n",
    "            classes.append(int(c))\n",
    "        \n",
    "    nr_graphs = len(classes) + 1\n",
    "    Vs, nodes_to_graph, node_labels, set_labels = read_node_labels(filename_nodes_to_graph, filename_node_labels, nr_graphs)\n",
    "    Es = read_edges(filename_edges, Vs, nodes_to_graph, node_labels, nr_graphs)\n",
    "    \n",
    "    return Vs[1:], Es[1:], node_labels, classes, set_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0734a5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/koki/Desktop/Data/Graphs/AIDS/AIDS_A.txt\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/koki/Desktop/Data/Graphs\"\n",
    "filename = \"AIDS\"\n",
    "Vs, Es, node_labels, classes, set_labels = read_graph(path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "643dac5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000, 2000, 38)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Vs), len(Es), len(classes), len(set_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4205d00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(classes), min(classes), max(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d8a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41f67039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31385"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6fd972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nx_graphs(Vs, Es):\n",
    "    '''\n",
    "    convert the nodes and edges into networkx graphs\n",
    "    '''\n",
    "    Gs = []\n",
    "    for i in range(len(Vs)):\n",
    "        V = Vs[i]\n",
    "        E = Es[i]\n",
    "        G = nx.Graph()\n",
    "        # G.add_nodes_from(V.keys())\n",
    "        for u,nbrs in E.items():\n",
    "            for v in nbrs:\n",
    "                G.add_edge(u, v)\n",
    "        Gs.append(G)\n",
    "    return Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f59694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gs = create_nx_graphs(Vs, Es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "622a84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(G, u, k, node_labels):\n",
    "    curr_node = u\n",
    "    walk = []\n",
    "    for i in range(k):\n",
    "        idx = random.randint(0,len(list(G[curr_node]))-1)\n",
    "        curr_node = list(G[curr_node])[idx]\n",
    "        walk.append(node_labels[curr_node])\n",
    "    return tuple(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37c4ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a number of random walks per node\n",
    "# such that walks consist of the provided node labels \n",
    "nr_walks_per_node = 10\n",
    "walks_sets = {}\n",
    "nodes = set()\n",
    "for G in Gs:\n",
    "    for u in G.nodes():\n",
    "        for j in range(nr_walks_per_node):\n",
    "            walk = random_walk(G, u, 4, node_labels)\n",
    "            walks_sets.setdefault(walk, set())\n",
    "            walks_sets[walk].add(u)\n",
    "            nodes.add(u)\n",
    "walks = {}\n",
    "for w, ws in walks_sets.items():\n",
    "    walks[w] = list(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11a1c13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87fa6648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 31175)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(walks), len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17d4e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityGen(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "        A generator class that will generate positive and negative node pairs.\n",
    "    \"\"\"    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 nodes,\n",
    "                 walks,\n",
    "                 nr_neg_samples, \n",
    "                 batch_size):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        :nodes: the nodes in all graphs\n",
    "        :walks: a hash map with the nodes per walk\n",
    "        :param node_to_int: a mapping of node ids to consecutive integers\n",
    "        :param nr_neg_samples: the number of negative samples for positive pair\n",
    "        :param batch_size: how many samples to generate\n",
    "        \"\"\"\n",
    "        assert nr_neg_samples >= 1\n",
    "        self.nodes = nodes\n",
    "        self.walks = walks # the labeled walks for sampling of positive examples\n",
    "        # self.node_to_int = node_to_int\n",
    "        self.nr_neg_samples = nr_neg_samples # by how mach to multiply the number pf positive samples\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "         \n",
    "    # how many samples to generate per epoch        \n",
    "    def __len__(self):\n",
    "        return 20000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i = 0\n",
    "        samples = []\n",
    "        labels = []\n",
    "        while i < self.batch_size:\n",
    "            i += 1\n",
    "            walk_idx = np.random.randint(len(self.walks))\n",
    "            walk = list(self.walks.keys())[walk_idx]\n",
    "            while len(self.walks[walk]) < 4:\n",
    "                walk_idx = np.random.randint(len(self.walks))\n",
    "                walk = list(self.walks.keys())[walk_idx]\n",
    "            u_idx = np.random.randint(len(self.walks[walk]))\n",
    "            v_idx = u_idx \n",
    "            while v_idx == u_idx:\n",
    "                v_idx = np.random.randint(len(self.walks[walk]))\n",
    "            \n",
    "            neg_idx = np.random.choice(len(nodes), self.nr_neg_samples)\n",
    "            neg = [self.nodes[idx] for idx in neg_idx]\n",
    "            \n",
    "            # generate positive samples from the random walk\n",
    "            samples.append((self.walks[walk][u_idx], self.walks[walk][v_idx]))\n",
    "            labels.append(1)\n",
    "            \n",
    "            # generate negative samples, a multiple of the walk length\n",
    "            samples.extend([(self.walks[walk][u_idx], n) for n in neg])\n",
    "            labels.extend(self.nr_neg_samples*[0])\n",
    "        return np.array(samples), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4eeb5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(nodes)\n",
    "gen = SimilarityGen(nodes, walks, nr_neg_samples=2, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65ebee5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[30080, 10672],\n",
       "        [30080, 26554],\n",
       "        [30080, 27547]]),\n",
       " array([1, 0, 0]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20befcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node2Vec(Model):\n",
    "    \"\"\"\n",
    "    The discriminative model that trains node embeddings. \n",
    "    Essentially, this is word2vec with negative sampling.\n",
    "    \"\"\"\n",
    "    def __init__(self, nr_nodes, embedding_dim, *args, **kwargs):\n",
    "        super(Node2Vec, self).__init__(self, args, kwargs)\n",
    "        self.nr_nodes = nr_nodes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.target_embedding = Embedding(nr_nodes,\n",
    "                                          embedding_dim,\n",
    "                                          embeddings_initializer=\"RandomNormal\",\n",
    "                                          input_length=1,\n",
    "                                          name=\"node_embedding\")\n",
    "        self.context_embedding = Embedding(nr_nodes,\n",
    "                                           embedding_dim,\n",
    "                                           embeddings_initializer=\"RandomNormal\",\n",
    "                                           input_length=1,\n",
    "                                           name=\"context_embedding\")\n",
    "        self.dots = Dot(axes=1)\n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, pair):\n",
    "        target, context = pair[:,0], pair[:,1]\n",
    "        word_emb = self.target_embedding(target)\n",
    "        context_emb = self.context_embedding(context)\n",
    "        dots = self.dots([context_emb, word_emb])\n",
    "        flat = self.flatten(dots)\n",
    "        return self.dense(flat)\n",
    "    \n",
    "    def summary(self):\n",
    "        x = Input(shape=(2,))\n",
    "        model = Model(inputs=[x], outputs=self.call(x))\n",
    "        return model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa7cbaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31385"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5efc78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a small graph, so the embedding dimensionality can be also small \n",
    "embedding_dim = 10\n",
    "nr_nodes = max(nodes)+1\n",
    "n2v = Node2Vec(nr_nodes=nr_nodes, embedding_dim=embedding_dim)\n",
    "n2v.build(input_shape=(nr_nodes, embedding_dim))\n",
    "n2v.compile(optimizer='adam',\n",
    "                 loss= 'binary_crossentropy', \n",
    "                 metrics=['accuracy', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ffbc356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None,)              0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None,)              0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "context_embedding (Embedding)   (None, 10)           313860      tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "node_embedding (Embedding)      (None, 10)           313860      tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           context_embedding[0][0]          \n",
      "                                                                 node_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1)            0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 627,722\n",
      "Trainable params: 627,722\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n2v.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffdb0a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 84s 4ms/step - loss: 0.5804 - accuracy: 0.7152 - auc: 0.6702\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 83s 4ms/step - loss: 0.4552 - accuracy: 0.8111 - auc: 0.7674\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 82s 4ms/step - loss: 0.4058 - accuracy: 0.8410 - auc: 0.8120\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 84s 4ms/step - loss: 0.3804 - accuracy: 0.8564 - auc: 0.8382\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 86s 4ms/step - loss: 0.3606 - accuracy: 0.8648 - auc: 0.8590\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 85s 4ms/step - loss: 0.3432 - accuracy: 0.8730 - auc: 0.8797\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 85s 4ms/step - loss: 0.3310 - accuracy: 0.8781 - auc: 0.9009\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 84s 4ms/step - loss: 0.3230 - accuracy: 0.8797 - auc: 0.9136\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 83s 4ms/step - loss: 0.3142 - accuracy: 0.8838 - auc: 0.9254\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 83s 4ms/step - loss: 0.3100 - accuracy: 0.8842 - auc: 0.9336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff584a8eaf0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2v.fit(gen, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59987c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = n2v.get_layer('node_embedding').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05aa195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings = {idx: emb for idx, emb in enumerate(embeddings)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78857d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5e11eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit_map_dim = 100\n",
    "poly_ts = PolynomialCountSketch(degree=2, gamma=10, random_state=1, n_components=explicit_map_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cf99cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the graph emebddings using explicit feature maps for the polynomial kernel.\n",
    "X = []\n",
    "for V in Vs:\n",
    "    graph_emb = np.array([.0 for _ in range(explicit_map_dim)])\n",
    "    for v in V:\n",
    "        emb_v = poly_ts.fit_transform([node_embeddings[v]])\n",
    "        graph_emb = np.add(graph_emb, emb_v[0])\n",
    "    graph_emb = graph_emb/len(V)\n",
    "    X.append(graph_emb)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f3c9ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "07daf9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8164784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, classes, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1afe9210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 100)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6e40b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)[:,1]\n",
    "    print(\"AUC score: \", auc(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d76ab6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg = LogisticRegression(C=1)\n",
    "model_rf = RandomForestClassifier(max_depth=12, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3ff2fbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score:  0.5689402810304449\n"
     ]
    }
   ],
   "source": [
    "# No luck with Logistic Regression\n",
    "train_and_evaluate(model_logreg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "34e4c05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score:  0.8322965456674473\n"
     ]
    }
   ],
   "source": [
    "# The random forest classifier looks much better\n",
    "train_and_evaluate(model_rf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2df8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b608e67d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
